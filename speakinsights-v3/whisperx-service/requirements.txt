# =============================================================================
# SpeakInsights v3 — WhisperX Service Dependencies
# =============================================================================
# NOTE: We do NOT need pyannote-audio (diarization) since SpeakInsights uses
# individual audio tracks per participant for speaker attribution.
# This avoids the torchcodec dependency that lacks ARM64 wheels.
# =============================================================================

# Web framework
fastapi>=0.104.0,<1.0.0
uvicorn[standard]>=0.24.0,<1.0.0
python-multipart>=0.0.6

# PyTorch (CPU — will be resolved by whisperx)
# torch and torchaudio are installed as whisperx transitive deps

# WhisperX core dependencies (installed manually to skip pyannote-audio)
faster-whisper>=1.0.0
ctranslate2>=4.0.0
transformers>=4.36.0
nltk>=3.9.0
pandas>=2.0.0
numpy>=2.1.0
omegaconf>=2.3.0

# Audio processing
soundfile>=0.12.0
tqdm

# pyannote sub-dependencies (needed for whisperx imports, sans torchcodec)
asteroid-filterbanks>=0.4.0
einops>=0.7.0
lightning>=2.0.0
safetensors>=0.4.0
rich>=13.0.0
pytorch-metric-learning>=2.0.0
matplotlib>=3.7.0
scipy>=1.10.0
scikit-learn>=1.3.0
sortedcontainers>=2.4.0
semver>=3.0.0
optuna>=3.0.0
docopt>=0.6.2
tabulate>=0.9.0
typer>=0.9.0
pyYAML>=6.0
torch-audiomentations>=0.12.0
opentelemetry-api>=1.34.0
opentelemetry-sdk>=1.34.0
opentelemetry-exporter-otlp>=1.34.0
pyannoteai-sdk>=0.3.0

# Utilities
python-dotenv>=1.0.0
huggingface-hub<1.0.0
